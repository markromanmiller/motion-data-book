[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "motion-data-book",
    "section": "",
    "text": "Overview\n[What is this book for]\nPart of it is motion in general…\nPart of it is a technical guide…\nThe process is (in order):",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#motion-data-analysis",
    "href": "index.html#motion-data-analysis",
    "title": "motion-data-book",
    "section": "Motion Data Analysis",
    "text": "Motion Data Analysis\nThe best place to start is with tidy data. Tidy data, for an experiment, is best in the BIDS format. This format specifies a file name and folder structure convention in addition to existing data structures (tsv) so that the structure of the experiment (conditions, participants, time points) is explicitly modeled rather than implicit.\nData already in this format can be processed using the rbids library. Documentation is largely not present, unfortunately.\nrbids is not specific to motion data, though, so working with motion data is done with the dddr library (see 3  dddr: Three-Dimensional Vector Operations in R). dddr has quite a few functions an decent documentation, but still has bugs.\nFinally, built upon rbids is what is currently called synsyn (for synchronizing on synchrony measurement). This “package” is currently just two functions that aid in applying the same function to either each person’s data (‘summarize_motion’) or pairs who attended the same session (‘summarize_motion_pairs’).",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "space-science.html",
    "href": "space-science.html",
    "title": "1  Thinking about Space, Scientifically",
    "section": "",
    "text": "Hall’s Proxemics\nSpace and Place\nExpectancy Violation Effect, etc.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Thinking about Space, Scientifically</span>"
    ]
  },
  {
    "objectID": "space-math.html",
    "href": "space-math.html",
    "title": "2  Thinking about Space, Mathematically",
    "section": "",
    "text": "2.1 Terminology",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking about Space, Mathematically</span>"
    ]
  },
  {
    "objectID": "space-math.html#terminology",
    "href": "space-math.html#terminology",
    "title": "2  Thinking about Space, Mathematically",
    "section": "",
    "text": "acceleration\nvelocity\nspeed\njerk\n\nsnap, crackle, pop, etc.\n\norientation (loops back)\nangular velocity (direction and magnitude)\nangular acceleration (direction and magnitude)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking about Space, Mathematically</span>"
    ]
  },
  {
    "objectID": "space-math.html#representing-position",
    "href": "space-math.html#representing-position",
    "title": "2  Thinking about Space, Mathematically",
    "section": "2.2 Representing Position",
    "text": "2.2 Representing Position\n\n3d Vector. Pretty straightforward.\nKnow your coordinate basis.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking about Space, Mathematically</span>"
    ]
  },
  {
    "objectID": "space-math.html#representing-rotations",
    "href": "space-math.html#representing-rotations",
    "title": "2  Thinking about Space, Mathematically",
    "section": "2.3 Representing Rotations",
    "text": "2.3 Representing Rotations\n\n2.3.1 Tait-Bryan (Euler) Angles\n\nCommonly used\nTechnically called tait-bryan angles in most situations\n\n\n\n\n2.3.2 Rotation Matrices\n\nnice when you don’t have a lot of them lined up by time\nbut they are pretty decent to train on (find that 6DOF paper)\n\n\n\n2.3.3 Quaternions\n(3b1b video) half-angle axis\nHandedness is the same as the positional axis handedness.\n\nI was confused earlier. For some reason, I had thought that the handedness of the quaternion’s axis-angle representation could be different from the underlying positional axes, but that’s not the case. As long as the quaternion multiplication is consistent, it’s the same handedness as the axes themselves. The quaternion’s X-value specifies a rotation from Y to Z always, it’s just the positional axes that determines whether that’s a left or right rotation.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Thinking about Space, Mathematically</span>"
    ]
  },
  {
    "objectID": "dddr.html",
    "href": "dddr.html",
    "title": "3  dddr: Three-Dimensional Vector Operations in R",
    "section": "",
    "text": "3.1 Tidy\nHere’s a common example of 3D data in a table of some sort:\nmessy_vectors\n\n# A tibble: 300 × 5\n   sensor_x sensor_y sensor_z temperature   time\n      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1     5     0          0            6.26 0.0333\n 2     4.98  0.00165    0.314        4.66 0.0667\n 3     4.94  0.00658    0.626        6.31 0.1   \n 4     4.88  0.0147     0.934        6.24 0.133 \n 5     4.80  0.0260     1.24         5.37 0.167 \n 6     4.71  0.0403     1.53         3.41 0.2   \n 7     4.59  0.0575     1.82         4.01 0.233 \n 8     4.46  0.0774     2.10         4.64 0.267 \n 9     4.31  0.0999     2.38         4.91 0.3   \n10     4.14  0.125      2.64         7.31 0.333 \n# ℹ 290 more rows\nLet’s calculate the speed of the sensor.\nmessy_vectors %&gt;%\n  mutate(\n    delta_t = time - lag(time),\n    velocity_x = (sensor_x - lag(sensor_x)) / delta_t,\n    velocity_y = (sensor_y - lag(sensor_y)) / delta_t,\n    velocity_z = (sensor_z - lag(sensor_x)) / delta_t,\n    speed = sqrt(velocity_x^2 + velocity_y^2 + velocity_z^2)\n  ) %&gt;% select(-starts_with(\"velocity\"))\n\n# A tibble: 300 × 7\n   sensor_x sensor_y sensor_z temperature   time delta_t speed\n      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1     5     0          0            6.26 0.0333 NA       NA  \n 2     4.98  0.00165    0.314        4.66 0.0667  0.0333 141. \n 3     4.94  0.00658    0.626        6.31 0.1     0.0333 131. \n 4     4.88  0.0147     0.934        6.24 0.133   0.0333 120. \n 5     4.80  0.0260     1.24         5.37 0.167   0.0333 109. \n 6     4.71  0.0403     1.53         3.41 0.2     0.0333  98.1\n 7     4.59  0.0575     1.82         4.01 0.233   0.0333  86.6\n 8     4.46  0.0774     2.10         4.64 0.267   0.0333  74.7\n 9     4.31  0.0999     2.38         4.91 0.3     0.0333  62.6\n10     4.14  0.125      2.64         7.31 0.333   0.0333  50.4\n# ℹ 290 more rows\nWhile there’s seven lines of code, there are only two operations, conceptually. This code takes the difference between separate positions to compute a velocity vector, and then computes the magnitude (size) of this velocity vector.\nMore importantly, this code is also buggy! Do you notice the line sensor_z - lag(sensor_x)? This doesn’t compute what we want. This error could be a simple copy-and-paste problem that would wouldn’t necessarily notice until you’re deep into writing other parts of your analysis. The more code you write, the more bugs you will have. Therefore, write less code and write less bugs.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>`dddr`: Three-Dimensional Vector Operations in R</span>"
    ]
  },
  {
    "objectID": "dddr.html#tidy",
    "href": "dddr.html#tidy",
    "title": "3  dddr: Three-Dimensional Vector Operations in R",
    "section": "",
    "text": "3.1.1 What is tidy data?\nIf the data were tidy, these steps would be less tedious.\nThe three criteria for tidy data are:\n\nEach column represents a variable\nEach row represents an observation\nEach cell represents a value\n\nBorrowing directly from Hadley again:\n\nWhy ensure that your data is tidy? There are two main advantages:\nThere’s a general advantage to picking one consistent way of storing data. If you have a consistent data structure, it’s easier to learn the tools that work with it because they have an underlying uniformity.\nThere’s a specific advantage to placing variables in columns because it allows R’s vectorized nature to shine. As you learned in Section 4.3.1 and Section 4.5.2, most built-in R functions work with vectors of values. That makes transforming tidy data feel particularly natural.\n\n\nWe think of position (or velocity) not as three variables, but as one variable represented by a triple of three numbers. Therefore, with tidy data, it should be only one column. This explains why working with XYZ data separately can be so tedious. This can be done with the vector3 function.\n\ntidy_vectors &lt;- messy_vectors %&gt;%\n  mutate(\n    sensor = vector3(x = sensor_x, y = sensor_y, z = sensor_z) #&lt;&lt;\n  ) %&gt;%\n  select(sensor, time, temperature)\n\ntidy_vectors\n\n# A tibble: 300 × 3\n                   sensor   time temperature\n                   &lt;vct3&gt;  &lt;dbl&gt;       &lt;dbl&gt;\n 1 (5   , 0      , 0    ) 0.0333        6.26\n 2 (4.98, 0.00165, 0.314) 0.0667        4.66\n 3 (4.94, 0.00658, 0.626) 0.1           6.31\n 4 (4.88, 0.0147 , 0.934) 0.133         6.24\n 5 (4.80, 0.0260 , 1.24 ) 0.167         5.37\n 6 (4.71, 0.0403 , 1.53 ) 0.2           3.41\n 7 (4.59, 0.0575 , 1.82 ) 0.233         4.01\n 8 (4.46, 0.0774 , 2.10 ) 0.267         4.64\n 9 (4.31, 0.0999 , 2.38 ) 0.3           4.91\n10 (4.14, 0.125  , 2.64 ) 0.333         7.31\n# ℹ 290 more rows\n\n\nLet’s calculate speed again, and see what the code looks like.\n\ntidy_vectors %&gt;%\n  mutate(\n    delta_t = time - lag(time),\n    sensor_velocity = (sensor - lag(sensor)) / delta_t,\n    sensor_speed = magnitude(sensor_velocity)\n  ) %&gt;%\n  select(sensor, time, temperature, sensor_speed)\n\nLook! Now we have two lines of code to represent our two conceptual operations. One creates the velocity vector, and the other calculates the speed vector. This is much closer to how we should be thinking of this kind of data.\n\n\n3.1.2 How do you tidy data with dddr?\ndddr revolves around two kinds of data: vector3 and quat.\n\n3.1.2.1 vector3\nThese represent 3D vectors, which can be position, velocity, acceleration, translation, direction, and other types of data.\n\n\n\n\n\n\nNote\n\n\n\nThe name vector3 highlights the fact there are two kinds of vectors being discussed here: 3-vectors, a geometric object with magnitude and direction, and R vectors, that represent ordered collections of one kind of data. This makes vector3 an R vector of 3-vectors.\n\n\n\n\n3.1.2.2 quat\nShort for quaternion, quats represent orientations, angular velocities, and rigid rotations. While somewhat mathematically complex, dddr is written to minimize how much you actually work with, somewhat inspired by the Unity game engine. If you do want a mathematical grounding for what quaternions are, watch a series of videos (1, 2) and interactive explainers (3) by Grant Sanderson and Ben Eater.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>`dddr`: Three-Dimensional Vector Operations in R</span>"
    ]
  },
  {
    "objectID": "dddr.html#visualize",
    "href": "dddr.html#visualize",
    "title": "3  dddr: Three-Dimensional Vector Operations in R",
    "section": "3.2 Visualize",
    "text": "3.2 Visualize\nData visualization is part of any data scientist’s toolbelt. Visualization is important for: - checking and cleaning data - understanding rich aspects of data - generating insights from data - reporting findings about data\nOne feature of spatial data is that it has a lot of human language associated with it. We can ask about the top view of a scene, and it has a meaning - and if we tell the computer how to translate from XYZ to “top view”, it can perform the translation for us.\n\n\n\nViewCube, Khan et al. (2008)\n\n\n\n3.2.1 Messy data means a messy visualization\nLet’s plot this data from a top view. If y is the vertical dimension, then let’s use x and z to plot.\n\nmessy_vectors %&gt;%\n  ggplot(aes(x = sensor_x, y = sensor_z, color = sensor_y)) +\n  geom_point() +\n  coord_equal()\n\n\n\n\n\n\n\n\nSome of the things this visualization can tell you are that:\n\nit spirals inward as you go counterclockwise (looking from the top view)\nthe back side (high Z) is higher (high Y)\n\nNothing seems wrong yet, right?\n\n\n3.2.2 Tidy data means a tidy visualization\nAgain, let’s plot this data from a top view, but this time, let’s do so with dddr.\n\ntidy_vectors %&gt;%\n  ggplot(aes(v = sensor)) +\n  geom_point() +\n  coord_look_at_top()\n\nWait, that’s not counterclockwise as you go in… That’s clockwise.\nIn the messy data plot, we accidentally chose the wrong axes - by choosing x for x and y for z, it meant that we had transformed the data like in a mirror, changing the handedness of the coordinate system.\nFollowing a semantic interpretation through all the spatial conventions can be tricky. This is a theme we’ll explore in a bit.\n\n\n3.2.3 ggplot2 extensions\nAs visible in the code above, dddr plugs directly into ggplot. Some of the handy pieces are:\n\ngeoms (geometric objects):\n\ngeom_point3, geom_path3\ngeom_spoke (direction)\n\ncoords (coordinate systems) are specified with coord_(frame)_(direction)\n\ncoord_look_at_top: Create the view as if you’re looking at the top of the object.\n\nAdditional theme parameters for the axis rose under dddr.rose.*\n\n\n\n3.2.4 Semantics\nIf you have worked with 3D data before, think of the coordinate system you know well.\n\nWhat direction is up?\nWhat direction is forward?\nWhat direction is right?\nIs the coordinate system left-handed or right-handed?\nWhich axis does “roll” go around?\nDoes a negative roll make the y-axis move towards the old x-axis, or vice versa?\nIf you have three rotations (roll, pitch, yaw) in what order are they applied?\nIf a pitch comes after a roll, does the pitch go around the old axis, or the new axis?\n\nHow many of the questions did you answer confidently and correctly?\nThere are 48 potential axis semantics, and 144 potential angle semantics. Some are simple reflections of each other; some are simple rotations; most are neither. This provides a significant challenge when working with “just” XYZ data.\nVectors in 3D space need to have some axis semantics. What meanings - up, down, forward, backward, right, left - are assigned to the positive and negative X-, Y-, and Z-axis? There are 48 different possible conventions, but only a handful are in common use.\nOnce the axis semantics are defined, rotations defined by rotation matrices or quaternions are also defined. However, rotations and orientations are often specified using Euler angles or Tait-Bryan angles such as yaw, pitch, and roll. To interpret these consistently, dddr uses angle semantics, specifying what yaw, pitch, and roll mean. What axis is each rotation performed around? What order do these rotations go in? Are the rotations applied to the axes of future rotations? Given three angles, there are 144 possible rotations that could be referred to.\ndddr provides some handy defaults in commonly used coordinate systems, such as this code for Unity’s coordinate system.\n\nset_dddr_semantics(axes = semantics_axes_unity, angles = semantics_angles_unity)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>`dddr`: Three-Dimensional Vector Operations in R</span>"
    ]
  },
  {
    "objectID": "dddr.html#transform",
    "href": "dddr.html#transform",
    "title": "3  dddr: Three-Dimensional Vector Operations in R",
    "section": "3.3 Transform",
    "text": "3.3 Transform\nOftentimes the data isn’t showing what you want, and you need to create, modify, amd summarize columns to get to a new result.\n\n3.3.1 Transforming vector3\nThe vector3 class supports a wide range of functions. In these examples, u, v, w are vector3s, q and p are quats, and x is a numeric.\n\nCreation: v &lt;- vector3(x = xs, y = ys, z = zs)\nField access: v$x, v$y, v$z\nVector properties: magnitude(v), direction(v)\nArithmetic: v + w, v - w, 2 * v, v / x\nR vector math: mean(v), sum(v), cumsum(v)\n3-vector math: dot(v, w), cross(v, w)\nSpatial operations:\n\nproject(v, onto=w), reject(v, from=w)\nangle_between(v, w, around=u), distance_between(v, w),\n\n\n\n\n3.3.2 Transforming with quat and rotate\nWorking with quaternions can be a little difficult, but when necessary, there are operations that support it:\n\nCreation: q &lt;- quat(w = ws, x = xs, y = ys, z = zs)\nMultiplication (composition): q2 &lt;- p * q\nConjugation (inversion): Conj(q)\nQuaternion equality: quat(1, 0, 0, 0) == quat(-1, 0, 0, 0)\n\nWorking in Tait-Bryan angles is more straightforward.\n\nCreate a quaternion: q &lt;- tait_bryan(yaw, pitch, roll)\nPull out the rotation values: yaw(q), pitch(q), roll(q)\n\nQuaternions are used to rotate.\n\nRotate using a quaternion: rotate(v, q)\nRotate around a point: rotate(v, q, origin = w)\nRotate through an angle around an axis: rotate(v, angle = x, axis = w)\nRotate along the shortest path implied by two vectors: rotate(v, from = w, to = u)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>`dddr`: Three-Dimensional Vector Operations in R</span>"
    ]
  },
  {
    "objectID": "dddr.html#using-dddr",
    "href": "dddr.html#using-dddr",
    "title": "3  dddr: Three-Dimensional Vector Operations in R",
    "section": "3.4 Using dddr",
    "text": "3.4 Using dddr\nInstallation is done through Github and devtools, as dddr is not ready for CRAN just yet.\n# if you have not installed \"devtools\"\ninstall.packages(\"devtools\")\n\n# For the most recent released version of dddr\ndevtools::install_github(\"markromanmiller/dddr@*release\")\n\n# For the development version of dddr\ndevtools::install_github(\"markromanmiller/dddr\")\nQuestions about dddr and bug reports are always appreciated! Email me at mmiller30 -at- iit -dot- edu, or file a bug report on the Github repository.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>`dddr`: Three-Dimensional Vector Operations in R</span>"
    ]
  },
  {
    "objectID": "key-measures.html",
    "href": "key-measures.html",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "",
    "text": "4.1 Position",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#position",
    "href": "key-measures.html#position",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "",
    "text": "4.1.1 Interpersonal Distance",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#orientation",
    "href": "key-measures.html#orientation",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.2 Orientation",
    "text": "4.2 Orientation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#velocity",
    "href": "key-measures.html#velocity",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.3 Velocity",
    "text": "4.3 Velocity",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#angular-velocity",
    "href": "key-measures.html#angular-velocity",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.4 Angular Velocity",
    "text": "4.4 Angular Velocity",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#speed",
    "href": "key-measures.html#speed",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.5 Speed",
    "text": "4.5 Speed",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#angular-speed",
    "href": "key-measures.html#angular-speed",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.6 Angular Speed",
    "text": "4.6 Angular Speed\nIt’s not yaw^2, pitch^2, roll^2\nit’s … code (should be a library function)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#acceleration",
    "href": "key-measures.html#acceleration",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.7 Acceleration",
    "text": "4.7 Acceleration",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#angular-acceleration",
    "href": "key-measures.html#angular-acceleration",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.8 Angular Acceleration",
    "text": "4.8 Angular Acceleration",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#jerk",
    "href": "key-measures.html#jerk",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.9 Jerk",
    "text": "4.9 Jerk",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#angular-jerk",
    "href": "key-measures.html#angular-jerk",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.10 Angular Jerk",
    "text": "4.10 Angular Jerk\n(human body tends to minimize)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#filtering",
    "href": "key-measures.html#filtering",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.11 Filtering",
    "text": "4.11 Filtering",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "key-measures.html#cross-correlation",
    "href": "key-measures.html#cross-correlation",
    "title": "4  Key Measures, Calculations, Interpretations",
    "section": "4.12 Cross-Correlation",
    "text": "4.12 Cross-Correlation",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Key Measures, Calculations, Interpretations</span>"
    ]
  },
  {
    "objectID": "bids.html",
    "href": "bids.html",
    "title": "5  BIDS (Brain Imaging Data Structure)",
    "section": "",
    "text": "link: https://bids-specification.readthedocs.io/en/stable/\nalso: https://docs.google.com/document/d/1iaaLKgWjK5pcISD1MVxHKexB3PZWfE2aAC5HF_pCZWo/edit",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>BIDS (Brain Imaging Data Structure)</span>"
    ]
  },
  {
    "objectID": "myrec.html",
    "href": "myrec.html",
    "title": "6  MYREC File Format",
    "section": "",
    "text": "6.1 File structure\nThe .myrec file is a ZIP file archive that contains several compressed files within it. This file structure is consistent across all .myrec files that I’ve encountered from June to December 2021. Once unzipped recursively, the file structure is:\nEach file is described below.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>MYREC File Format</span>"
    ]
  },
  {
    "objectID": "myrec.html#file-structure",
    "href": "myrec.html#file-structure",
    "title": "6  MYREC File Format",
    "section": "",
    "text": "count.txt\nmaster (ZIP)\n\nmaster.txt\n\nstream0 (ZIP)\n\naudioothers.mp3\nevents.txt\nstream.txt\n\nstream1 (ZIP)\n…",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>MYREC File Format</span>"
    ]
  },
  {
    "objectID": "myrec.html#file-contents",
    "href": "myrec.html#file-contents",
    "title": "6  MYREC File Format",
    "section": "6.2 File Contents",
    "text": "6.2 File Contents\n\n6.2.1 count.txt\nThis file is a one-line file in what appears to be key-value pairs. Pairs are separated by a semicolon, and keys and values are separated by a pipe.\n\nstreamCount: the number of streamN archives in the top-level archive, where N is a non-negative integer.\nsceneID: the environment in which the recording takes place.\n\n\n\n6.2.2 master.txt\nThis file gives information about the recording as a whole. For example, there is some information about the timing of the different streamN files. Information about the recorder’s and participants’ avatars is also stored here. While its file suffix is .txt, it is in fact a JSON file. There are too many entries to be described here.\n\n\n6.2.3 audioothers.mp3\nThis file is an mp3 file recording the spoken audio. Presumably, based on its name, it only captures audio spoken by people who were not recording, but this has not been verified directly. This file only exists in streams in which someone was speaking. In order to create an audio track for the entire file, one needs to create a space for silence for the duration of each stream without this file.\n\n\n6.2.4 events.txt\nThis file mainly deals with changes that aren’t necessarily tied to an avatar. It is also a JSON file despite its suffix. Much of the activity in this file is related to IFX motion and usage. Other than hints given by the names in the keys, it is not understood what these values refer to specifically.\n\n\n6.2.5 stream.txt\nThis file is what appears to be a custom format storing the values of several variables for several users over a number of frames (140, in 2021). Breaking down each level from largest granularity to smallest:\nUsers are demarcated by one or multiple leading &gt; characters. Each successive &gt; increments the user’s ID by one. For example, if users 1, 2, 5, and 6 are in the recording, then the &gt; characters will be distributed as follows: &gt; (1’s data) &gt; (2’s data) &gt;&gt;&gt; (5’s data) &gt; (6’s data). Note that at the point in the file with user data, the user ID is equal to the number of &gt;s that precede it in the entire file.\nVariables are demarcated with a name and one | character at the beginning, and one ; character at the end. Variable names follow the format &lt;name&gt;&lt;type&gt;x. Here, &lt;type&gt; can be int for integer, flo for float, or v3 for a 3D vector type.\nThe spatial variables we used had a &lt;name&gt; following the convention &lt;tracked_point&gt;(Positions|Rotations). The tracked points included AvaRoot, Head, LeftHand, RightHand, LeftFoot, RightFoot, and Hip. For all the data collected in the summer and fall 2021 studies, the values for the feet and the hips were unused and not meaningful. AvaRoot stands for Avatar Root, and it defined the coordinate transformation from the coordinate space for Head, LeftHand, and RightHand into the global coordinate system.\nThe only other variable we used was LipSyncAverageflox, which indicated the amount of an avatar’s lip-flapping and was presumably based upon volume. There were several other values that are included in the recording but we have not used, such as IFXScaleflox, (Left|Right)TriggerPressedintx, (Left|Right)HandPointingintx, (Left|Right)HandLaserPointerintx (Left|Right)HandWhiteboardingintx, TabletOutintx, AvatarEmotionStateintx, RaisingHandintx, Clappingintx, OutfitOverrideStateintx, UseSitTriggerOverridesintx IsAwayintx, IsInSitTriggerintx, (Left|Right)HandWhiteboardEmitterPositionsv3x, IfxPositionsv3x, and IfxRotationsv3x.\nSamples are demarcated with with infixed |. Any values that are equal to the previous value are not included, so several variables often are written |0|||||....\n3D Vectors are demarcated in a special way relative to other data types. The three elements of the vector are separated with infix &lt; symbols, and changes propagate along dimension individually. For example, the value |&lt;2.345&lt;| means the y-value changed to 2.345, but the x- and z- values remained the same. Position and rotation vectors were written the same way; they only difference in the data itself is the variable name discussed above. Positions are interpreted as X&lt;Y&lt;Z, where axis conventions are used according to Unity (Y up, Z out, left-handed). Rotations are interpreted as pitch&lt;yaw&lt;roll, where angle conventions are also used according to Unity.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>MYREC File Format</span>"
    ]
  },
  {
    "objectID": "myrec.html#interpretations",
    "href": "myrec.html#interpretations",
    "title": "6  MYREC File Format",
    "section": "6.3 Interpretations",
    "text": "6.3 Interpretations\n\n6.3.1 Root, Head, Hands / Physical, Virtual, and Visible Motion\nENGAGE separates out motion into four related channels. AvaRoot stands for Avatar Root, and it defines the coordinate transformation from the coordinate space for Head, LeftHand, and RightHand into the global coordinate system. What is particularly nice about ENGAGE’s data being in this format is that one can distinguish between physical, virtual, and visible motion.\nWith virtual reality, what is visible to others in the virtual environment is a result of two kinds of motion: physical and virtual motion.\n\nPhysical motion is what it sounds like: it’s motion in the physical [real] world. Moving one’s real hand creates physical motion. Calculating the physical position and motion is just as easy as selecting just the Head, LeftHand, and RightHand columns.\nVirtual motion is motion that is caused by some process that doesn’t directly represent the motion. For example, teleporting is a kind of virtual motion, and so is pressing a button and moving in the virtual world. The thing that caused that motion wasn’t literally motion, it was something translated by the system. This is given by just the AvaRoot columns, because it’s the same in ENGAGE across all the three other tracked points.\nVisible motion is the motion that is (usually) the vector sum of these two types of motion. This is the way ENGAGE does it, at least. It is the motion with the virtual world as its framing. To calculate the visible position using dddr and ungage, take the example of this code:\n\nread_tsv(file_path, col_types = list(Timestamp = col_time(\"%H:%M:%OS\"))) %&gt;%\n  bundle(\n    Root = \"AvaRoot_Pos{v}\",\n    RootRot = \"AvaRoot_Rot{ed}\",\n    PhysicalHead = \"Head_Pos{v}\",\n    PhysicalHeadRot = \"Head_Rot{ed}\"\n  ) %&gt;%\n  select(Timestamp, Root, RootRot, PhysicalHead, PhysicalHeadRot) %&gt;%\n  mutate(\n    # convert to visible motion\n    VisibleRawHead = Root + rotate(PhysicalHead, RootRot),\n    VisibleRawHeadRot = rotate(PhysicalHeadRot, RootRot, as = \"orientation\")\n  )\nIt should be noted this taxonomy is not complete. For example, it doesn’t allow for describing alternative methods of motion, such as redirected walking or visuo-haptic illusions. Nevertheless, it is a useful description of motion when working with ENGAGE.\n\n\n6.3.2 others…\n[[more could be written here — a good threshold for smooth motion is 3.05 m/s]]",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>MYREC File Format</span>"
    ]
  },
  {
    "objectID": "converting-myrec-bids.html",
    "href": "converting-myrec-bids.html",
    "title": "7  Converting MYREC to BIDS",
    "section": "",
    "text": "7.1 Extracting Myrec\n(see the Rmd file I sent over a long while ago)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Converting MYREC to BIDS</span>"
    ]
  },
  {
    "objectID": "converting-myrec-bids.html#forming-to-bids",
    "href": "converting-myrec-bids.html#forming-to-bids",
    "title": "7  Converting MYREC to BIDS",
    "section": "7.2 Forming to BIDS",
    "text": "7.2 Forming to BIDS",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Converting MYREC to BIDS</span>"
    ]
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "8  Examples of Social Analysis",
    "section": "",
    "text": "8.1 libraries\nsynsyn (https://github.com/markromanmiller/synsyn) dddr",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Examples of Social Analysis</span>"
    ]
  },
  {
    "objectID": "examples.html#total-motion-over-time",
    "href": "examples.html#total-motion-over-time",
    "title": "8  Examples of Social Analysis",
    "section": "8.2 total motion over time",
    "text": "8.2 total motion over time",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Examples of Social Analysis</span>"
    ]
  },
  {
    "objectID": "examples.html#distance-between-people",
    "href": "examples.html#distance-between-people",
    "title": "8  Examples of Social Analysis",
    "section": "8.3 distance between people",
    "text": "8.3 distance between people\nDistance between people can be tricky because usually distance can be measured over time. The question becomes how collapse a time series of values into one value.\nA very simple option is to simply take the average. In some highly controlled situations, this is acceptable. The assumption that one makes when averaging is that all the distances and times are roughly equally important. This makes sense when two people are facing each other and interacting for the vast majority of time, and there are no outliers in terms of distance.\nIn some work (for example, the study “Proxemics and Gaze in Virtual Environments” that I led at IEEE VR 2023), I instead went with a not-quite-minimum. This, to me, better captured the fact that interpersonal distance is more about how close you are without feeling uncomfortable. The reason this was used instead of minimum was because occastionally people might teleport too close to each other and need to adjust their distance.\nCode for both is below.\n# Take the file, read it, and get virtual position of root, and physical position of head, and find visible position.\npreprocess &lt;- function(file_path, session_id, participant_id, ...) {\n  # exactly one file per person\n  read_tsv(file_path, col_types = list(Timestamp = col_time(\"%H:%M:%OS\")), progress = F) %&gt;%\n    bundle(\n      Root = \"Root_Pos{v}\",\n      RootRot = \"Root_Rot{ed}\",\n      RawHead = \"Head_Pos{v}\"\n    ) %&gt;%\n    select(Timestamp, Root, RootRot, RawHead) %&gt;%\n    mutate(session_id = session_id) %&gt;%\n    mutate(\n      # convert to visible motion\n      VisibleRawHead = Root + rotate(RawHead, RootRot)\n    )\n}\n\n# Take average distance between participants\naverage_distance_between &lt;- function(px_data, py_data) {\n  joined &lt;- inner_join(px_data, py_data, by = c(\"Timestamp\"))\n\n  if (nrow(joined) == 0) {\n    return (NULL)\n  }\n\n  joined %&gt;%\n    mutate(\n      dist = distance_between(VisibleRawHead.y, VisibleRawHead.x) %&gt;%\n    ) %&gt;%\n    summarize(\n      dist = mean(dist)\n    )\n}\n\n# Take the minimum distance between participants, ignoring 5 seconds worth of motion data\naverage_distance_between &lt;- function(px_data, py_data) {\n  joined &lt;- inner_join(px_data, py_data, by = c(\"Timestamp\"))\n\n  if (nrow(joined) == 0) {\n    return (NULL)\n  }\n\n  joined %&gt;%\n    mutate(\n      dist = distance_between(VisibleRawHead.y - VisibleRawHead.x) %&gt;%\n    ) %&gt;%\n    summarize(\n      # Notice that the only difference is the summarize function\n      dist = sort(dist)[150]\n    )\n}\n\n# Now that the functions are defined, run them on the BIDS data\nresults &lt;- bd %&gt;%\n  bids_motion() %&gt;%\n  summarize_motion_pairs(\n    relate = select_which_motion_relation_function_you_want,\n    preprocess = preprocess,\n    ordered = T,\n    #head = 5,\n    progress = T\n  ) %&gt;%\n  unnest(result)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Examples of Social Analysis</span>"
    ]
  },
  {
    "objectID": "examples.html#heatmap",
    "href": "examples.html#heatmap",
    "title": "8  Examples of Social Analysis",
    "section": "8.4 Heatmap",
    "text": "8.4 Heatmap",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Examples of Social Analysis</span>"
    ]
  },
  {
    "objectID": "examples.html#gaze-distribution",
    "href": "examples.html#gaze-distribution",
    "title": "8  Examples of Social Analysis",
    "section": "8.5 Gaze distribution",
    "text": "8.5 Gaze distribution",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Examples of Social Analysis</span>"
    ]
  },
  {
    "objectID": "examples.html#mutual-gaze",
    "href": "examples.html#mutual-gaze",
    "title": "8  Examples of Social Analysis",
    "section": "8.6 Mutual gaze",
    "text": "8.6 Mutual gaze\n# Load libraries\nlibrary(tidyverse)\ndevtools::load_all(\"~/thesis/multiverse/\")\ndevtools::load_all(\"~/work/dddr\")\ndevtools::load_all(\"~/thesis/rbids/\")\ndevtools::load_all(\"~/thesis/synsyn/\")\n\n# load BIDS dataset\nbd &lt;- bids(\"/media/mark/mrm-thesis-files/virtual-summer/bids-standard/vhil-2021-summer/\")\n\n# let dddr know that we're working with Unity's axis and angles conventions.\nset_dddr_semantics(axes = semantics_axes_unity, angles = semantics_angles_unity)\n\n# Take the file, read it, and get virtual position of root, and physical position of head, and find visible position.\npreprocess &lt;- function(file_path, session_id, participant_id, ...) {\n  # exactly one file per person\n  read_tsv(file_path, col_types = list(Timestamp = col_time(\"%H:%M:%OS\")), progress = F) %&gt;%\n    bundle(\n      Root = \"Root_Pos{v}\",\n      RootRot = \"Root_Rot{ed}\",\n      RawHead = \"Head_Pos{v}\",\n      RawHeadRot = \"Head_Rot{ed}\"\n    ) %&gt;%\n    select(Timestamp, Root, RootRot, RawHead, RawHeadRot) %&gt;%\n    mutate(session_id = session_id) %&gt;%\n    mutate(\n      # convert to visible motion\n      VisibleRawHead = Root + rotate(RawHead, RootRot),\n      VisibleRawHeadRot = rotate(RawHeadRot, RootRot, as = \"orientation\")\n    )\n}\n\n# take two participant's placement, and calculate whether they're looking at each other or if X is looking at Y.\nrelate_intrinsic_yp &lt;- function(px_data, py_data) {\n  joined &lt;- inner_join(px_data, py_data, by = c(\"Timestamp\"))\n\n  if (nrow(joined) == 0) {\n    return (NULL)\n  }\n\n  joined %&gt;%\n    #slice_sample(prop = 0.01) %&gt;%\n    mutate(\n      y_from_x = angle_between(VisibleRawHead.y - VisibleRawHead.x, vector3(0, 0, 1) %&gt;% rotate(VisibleRawHeadRot.x)) &lt; 15/180 * pi,\n      x_from_y = angle_between(VisibleRawHead.x - VisibleRawHead.y, vector3(0, 0, 1) %&gt;% rotate(VisibleRawHeadRot.y)) &lt; 15/180 * pi,\n      mutual = y_from_x & x_from_y\n    ) %&gt;%\n    select(\n      Timestamp, y_from_x, mutual\n    )\n}\n\n# This function takes several pairs' worth of data and collapses them to one timeframe for each person.\ngroup_summary_align_and_boolean &lt;- function(list_df) {\n  list_df %&gt;%\n    bind_rows() %&gt;%\n    unnest(result) %&gt;%\n    group_by(participant_id_x, Timestamp) %&gt;%\n    summarize(\n      y_from_x = any(y_from_x),\n      mutual = any(mutual),\n      .groups = \"drop_last\"\n    ) %&gt;%\n    summarize(\n      social_attention = mean(y_from_x, na.rm = T),\n      mutual_gaze = mean(mutual, na.rm = T),\n      total_frames = n(),\n      na_social_attention_frames = sum(is.na(y_from_x)),\n      na_mutual_gaze_frames = sum(is.na(mutual)),\n      .groups = \"drop\"\n    ) %&gt;%\n    group_nest(.key = \"result\")\n}\n\n# Now that the functions are defined, run them on the BIDS data\nresults &lt;- bd %&gt;%\n  bids_motion() %&gt;%\n  #filter(session_id %&gt;% endsWith(\"section1\")) %&gt;%\n  #filter(session_id == \"week7section8\") %&gt;%\n  summarize_motion_pairs(\n    relate = relate_intrinsic_yp,\n    preprocess = preprocess,\n    group_summary = group_summary_align_and_boolean,\n    ordered = T,\n    #head = 5,\n    progress = T\n  ) %&gt;%\n  unnest(result)\n\n# Output the file with a timestamp to make it unique.\noutput_file &lt;- paste0(\"results_\", strftime(Sys.time(), format = \"%y_%m_%d_%H%M%S\"), \".csv\")\ncat(\"Output file at\", output_file)\n\nresults %&gt;% write_csv(output_file)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Examples of Social Analysis</span>"
    ]
  },
  {
    "objectID": "all-measures.html",
    "href": "all-measures.html",
    "title": "9  All Measures",
    "section": "",
    "text": "9.1 Position",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>All Measures</span>"
    ]
  },
  {
    "objectID": "all-measures.html#position",
    "href": "all-measures.html#position",
    "title": "9  All Measures",
    "section": "",
    "text": "9.1.1 Interpersonal Distance",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>All Measures</span>"
    ]
  },
  {
    "objectID": "all-measures.html#orientation",
    "href": "all-measures.html#orientation",
    "title": "9  All Measures",
    "section": "9.2 Orientation",
    "text": "9.2 Orientation\n\n9.2.1 Gaze for an object within a time",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>All Measures</span>"
    ]
  },
  {
    "objectID": "all-measures.html#velocity",
    "href": "all-measures.html#velocity",
    "title": "9  All Measures",
    "section": "9.3 Velocity",
    "text": "9.3 Velocity",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>All Measures</span>"
    ]
  },
  {
    "objectID": "all-measures.html#angular-velocity",
    "href": "all-measures.html#angular-velocity",
    "title": "9  All Measures",
    "section": "9.4 Angular Velocity",
    "text": "9.4 Angular Velocity",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>All Measures</span>"
    ]
  },
  {
    "objectID": "all-measures.html#speed",
    "href": "all-measures.html#speed",
    "title": "9  All Measures",
    "section": "9.5 Speed",
    "text": "9.5 Speed",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>All Measures</span>"
    ]
  },
  {
    "objectID": "all-measures.html#angular-speed",
    "href": "all-measures.html#angular-speed",
    "title": "9  All Measures",
    "section": "9.6 Angular Speed",
    "text": "9.6 Angular Speed\nIt’s not yaw^2, pitch^2, roll^2\nit’s … code (should be a library function)\n(human body tends to minimize)",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>All Measures</span>"
    ]
  },
  {
    "objectID": "all-measures.html#yawpitchroll-speed",
    "href": "all-measures.html#yawpitchroll-speed",
    "title": "9  All Measures",
    "section": "9.7 Yaw/Pitch/Roll Speed",
    "text": "9.7 Yaw/Pitch/Roll Speed",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>All Measures</span>"
    ]
  }
]